{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thie notebook explores the multilayer perceptron for binary text classification, using the keras library.  Before starting, be sure to install the following versions of tensorflow and keras (for python 3.7):\n",
    "\n",
    "```sh\n",
    "pip install tensorflow==1.13.0-rc2\n",
    "pip install keras==2.2.4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for idx,line in enumerate(file):\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            # assumes text is tokenized\n",
    "            text=cols[1]\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"../data/lmrd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory)\n",
    "devX, devY=read_data(\"%s/dev.tsv\" % directory)\n",
    "testX, testY=read_data(\"%s/test.tsv\" % directory)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000, analyzer=str.split, lowercase=True, strip_accents=None, binary=True)\n",
    "X_train = vectorizer.fit_transform(trainX)\n",
    "X_dev = vectorizer.transform(devX)\n",
    "X_test = vectorizer.transform(testX)\n",
    "\n",
    "_,vocabSize=X_train.shape\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)\n",
    "Y_test=le.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(vocabSize,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model):\n",
    "    print (model.summary())\n",
    "\n",
    "    # stop training early when the val_loss on the dev data stops going down\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=10,\n",
    "        verbose=0, \n",
    "        mode='auto')\n",
    "\n",
    "    # when training, save the model that has the best val_loss on the dev data\n",
    "    modelName=\"mymodel.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(modelName, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "    # train\n",
    "    model.fit(X_train, Y_train, \n",
    "                validation_data=(X_dev, Y_dev),\n",
    "                epochs=5,\n",
    "                callbacks=[checkpoint, early_stopping])\n",
    "    \n",
    "    # load best trained model (from checkpoint)\n",
    "    model.load_weights(modelName)\n",
    "\n",
    "    dev_loss, dev_accuracy = model.evaluate(X_dev, Y_dev, batch_size=128)\n",
    "    print(\"Dev Accuracy: %.3f\" % dev_accuracy)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "    print(\"Test Accuracy: %.3f\" % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(mlp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
