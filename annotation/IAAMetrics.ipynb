{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates interannotator agreement rates for data with categorical labels (using Cohen's $\\kappa$) and real values (using Krippendorff's $\\alpha$).  We calculate these rates for two tasks: subjectivity/objectivity and suspense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.metrics import interval_distance, binary_distance \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_alpha(annotation_triples):\n",
    "\n",
    "    t = AnnotationTask(annotation_triples, distance=interval_distance)\n",
    "    result = t.alpha()\n",
    "    print(\"%.3f\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_kappa(annotation_triples):\n",
    "\n",
    "    t = AnnotationTask(annotation_triples, distance=interval_distance)\n",
    "    result = t.kappa()\n",
    "    print(\"%.3f\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annos(filename):\n",
    "    annos=[]\n",
    "    sentences=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "\n",
    "        header=file.readline().rstrip().split(\"\\t\")\n",
    "            \n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            annos.append(float(cols[0]))\n",
    "            sentences.append(cols[1])\n",
    "    return annos, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_anno_list(annos, annotator_id):\n",
    "    converted=[]\n",
    "    for idx, anno in enumerate(annos):\n",
    "        converted.append((annotator_id, idx, anno))\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno1_filename=\"path to your filename name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno2_filename=\"path to group annotation file here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno1, sentences=read_annos(anno1_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno2, _=read_annos(anno2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(anno1) != len(anno2):\n",
    "    print (\"Different number of annotations: %s vs. %s\" % len(anno1), len(anno2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out sentences with different annotations\n",
    "for idx in range(len(anno1)):\n",
    "    if abs(anno1[idx]-anno2[idx]) >= 1:\n",
    "        print(\"%s\\t%s\\t%s\" % (anno1[idx], anno2[idx], sentences[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno1=convert_anno_list(anno1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno2=convert_anno_list(anno2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectivity is a binary rating, so use Cohen's $\\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_kappa(anno1 + anno2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspense is a real-valued rating, so use Krippendorff's $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krippendorff_alpha(anno1 + anno2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
